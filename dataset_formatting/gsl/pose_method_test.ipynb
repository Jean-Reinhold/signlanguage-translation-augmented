{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "OUT_DIR = \".temp\"\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "\tos.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713266500.309229 3984003 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1713266500.322471 3984353 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.54.14), renderer: NVIDIA TITAN X (Pascal)/PCIe/SSE2\n",
      "100%|██████████| 111/111 [00:15<00:00,  7.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pose_format.utils.holistic import load_holistic\n",
    "\n",
    "\n",
    "DATA_DIR = \"/mnt/data3/slt-datasets-3/GSL/GSL_continuous/health1_signer1_rep1_sentences/sentences0000\" \n",
    "\n",
    "holistic_config = {\n",
    "\t\"model_complexity\": 2,\n",
    "\t\"refine_face_landmarks\": True,\n",
    "\t\"min_detection_confidence\": 0.2,\n",
    "\t\"min_tracking_confidence\": 0.2,\n",
    "}\n",
    "\n",
    "files = sorted(os.listdir(DATA_DIR))\n",
    "frames = [cv2.imread(os.path.join(DATA_DIR, file)) for file in files]\n",
    "pose = load_holistic(frames, 30, frames[0].shape[1], frames[0].shape[0], progress=True, additional_holistic_config=holistic_config)\n",
    "with open(f\"{OUT_DIR}/example.pose\", \"wb\") as f:\n",
    "\tpose.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose_format.pose import Pose\n",
    "\n",
    "data_buffer = open(f\"{OUT_DIR}/example.pose\", \"rb\").read()\n",
    "pose = Pose.read(data_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSE_LANDMARKS',\n",
       " 'FACE_LANDMARKS',\n",
       " 'LEFT_HAND_LANDMARKS',\n",
       " 'RIGHT_HAND_LANDMARKS',\n",
       " 'POSE_WORLD_LANDMARKS']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.name for p in pose.header.components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose_format.utils.pose_converter import convert_pose\n",
    "\n",
    "components = [p for p in pose.header.components]# if p.name != \"POSE_LANDMARKS\"]\n",
    "pose = convert_pose(pose, components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSE_LANDMARKS',\n",
       " 'FACE_LANDMARKS',\n",
       " 'LEFT_HAND_LANDMARKS',\n",
       " 'RIGHT_HAND_LANDMARKS',\n",
       " 'POSE_WORLD_LANDMARKS']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.name for p in pose.header.components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.typing import NDArray\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from skvideo.io import vwrite\n",
    "\n",
    "\n",
    "def draw_keypoints(\n",
    "\t\tframe,\n",
    "        frame_keypoints,\n",
    "        size: int = 5,\n",
    "        threshold: float = 0.5,\n",
    "        color: int | None = None):\n",
    "\t'''Draw keypoints in the frame'''\n",
    "\tfr = frame.copy()\n",
    "\tfor i, (x, y, z) in enumerate(frame_keypoints):\n",
    "\t\t# check if x or y are masked\n",
    "\t\tif np.ma.is_masked(x) or np.ma.is_masked(y) or np.isnan(x) or np.isnan(y):\n",
    "\t\t\t# print(x.data, y.data)\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\tfr[int(y)-size:int(y)+size:,int(x)-size:int(x)+size] = color if color is not None else 255-fr[int(y)-size:int(y)+size:,int(x)-size:int(x)+size]\n",
    "\treturn fr\n",
    "\n",
    "def store_video(video: NDArray[np.uint8], name: str, dir: str = '.temp'):\n",
    "\tif not os.path.exists(dir):\n",
    "\t\tos.makedirs(dir)\n",
    "\tvwrite(f\"{dir}/{name}.mp4\", video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 1, 586, 3)\n"
     ]
    }
   ],
   "source": [
    "keypoints = pose.body.data\n",
    "h, w = 480, 848\n",
    "video = np.zeros((keypoints.shape[0], h, w, 3), np.dtype('uint8'))\n",
    "print(keypoints.shape)\n",
    "for i_frame in range(keypoints.shape[0]):\n",
    "\tvideo[i_frame] = draw_keypoints(video[i_frame], keypoints[i_frame][0], size=2)\n",
    "store_video(video, 30, \"example_adhoc.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\u001b[32m08:26:09\u001b[0m :: \u001b[1;35m  WriteGear  \u001b[0m :: \u001b[1;31m\u001b[2;33mWARNING \u001b[0m :: \u001b[1;37mOptional `-disable_ffmpeg_window` flag is only available on Windows OS with `logging=False`. Discarding!\u001b[0m\n",
      "111it [00:07, 15.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from pose_format.pose_visualizer import PoseVisualizer\n",
    "\n",
    "\n",
    "v = PoseVisualizer(pose)\n",
    "v.save_video(f\"{OUT_DIR}/example_b.mp4\", v.draw())\n",
    "# v.save_gif(f\"{OUT_DIR}/example.gif\", v.draw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With mediapipe only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m keypoints\n\u001b[1;32m     27\u001b[0m VID_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/data3/slt-datasets-3/GSL/GSL_mirror/videos/health1_signer1_rep1_sentences_sentences0000.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m video \u001b[38;5;241m=\u001b[39m vread(VID_PATH)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(video)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m frames\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m run_holistic(video)\n",
      "File \u001b[0;32m~/anaconda3/envs/slt_datasets/lib/python3.11/site-packages/skvideo/io/io.py:144\u001b[0m, in \u001b[0;36mvread\u001b[0;34m(fname, height, width, num_frames, as_grey, inputdict, outputdict, backend, verbosity)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_grey:\n\u001b[1;32m    142\u001b[0m     outputdict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-pix_fmt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 144\u001b[0m reader \u001b[38;5;241m=\u001b[39m FFmpegReader(fname, inputdict\u001b[38;5;241m=\u001b[39minputdict, outputdict\u001b[38;5;241m=\u001b[39moutputdict, verbosity\u001b[38;5;241m=\u001b[39mverbosity)\n\u001b[1;32m    145\u001b[0m T, M, N, C \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mgetShape()\n\u001b[1;32m    147\u001b[0m videodata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((T, M, N, C), dtype\u001b[38;5;241m=\u001b[39mreader\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/slt_datasets/lib/python3.11/site-packages/skvideo/io/ffmpeg.py:44\u001b[0m, in \u001b[0;36mFFmpegReader.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m _HAS_FFMPEG, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find installation of real FFmpeg (which comes with ffprobe).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28msuper\u001b[39m(FFmpegReader,\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/slt_datasets/lib/python3.11/site-packages/skvideo/io/abstract.py:87\u001b[0m, in \u001b[0;36mVideoReaderAbstract.__init__\u001b[0;34m(self, filename, inputdict, outputdict, verbosity)\u001b[0m\n\u001b[1;32m     85\u001b[0m parts \u001b[38;5;241m=\u001b[39m frtxt\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mfloat(parts[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.\u001b[39m:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputfps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_FRAMERATE\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/slt_datasets/lib/python3.11/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from skimage.io import imread\n",
    "from numpy.typing import NDArray\n",
    "from mediapipe import solutions\n",
    "\n",
    "\n",
    "JOINTS_SIZE = np.float16\n",
    "\n",
    "def process_keys(frame_keypoints) -> NDArray[JOINTS_SIZE]:\n",
    "\tpose = [[landmark.x, landmark.y, landmark.z] for landmark in frame_keypoints.pose_landmarks.landmark] if frame_keypoints.pose_landmarks is not None else [[np.nan]*3]*33\n",
    "\tface = [[landmark.x, landmark.y, landmark.z] for landmark in frame_keypoints.face_landmarks.landmark] if frame_keypoints.face_landmarks is not None else [[np.nan]*3]*468\n",
    "\trhand = [[landmark.x, landmark.y, landmark.z] for landmark in frame_keypoints.right_hand_landmarks.landmark] if frame_keypoints.right_hand_landmarks is not None else [[np.nan]*3]*21\n",
    "\tlhand = [[landmark.x, landmark.y, landmark.z] for landmark in frame_keypoints.left_hand_landmarks.landmark] if frame_keypoints.left_hand_landmarks is not None else [[np.nan]*3]*21\n",
    "\treturn np.stack(pose + face + rhand + lhand).astype(JOINTS_SIZE)\n",
    "\n",
    "def run_holistic(frames: NDArray[np.uint8]) -> NDArray[JOINTS_SIZE]:\n",
    "\tkeypoints = []\n",
    "\twith solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic: # type: ignore\n",
    "\t\tfor frame in frames:\n",
    "\t\t\tkeypoints.append(holistic.process(frame))\n",
    "\treturn keypoints\n",
    "\n",
    "\n",
    "DATA_DIR = \"/mnt/data3/slt-datasets-3/GSL/GSL_continuous/health1_signer1_rep1_sentences/sentences0000\" \n",
    "\n",
    "files = sorted(os.listdir(DATA_DIR))\n",
    "video = np.stack([imread(os.path.join(DATA_DIR, file)) for file in files])\n",
    "\n",
    "print(f\"Loaded {len(video)} frames\")\n",
    "\n",
    "keypoints = run_holistic(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 543, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_keys = np.array(list(map(process_keys, keypoints)))\n",
    "processed_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(\n",
    "\t\tframe,\n",
    "        frame_keypoints,\n",
    "\t\th: int,\n",
    "\t\tw: int,\n",
    "        size: int = 5,\n",
    "        color: int | None = None):\n",
    "\t'''Draw keypoints in the frame'''\n",
    "\tfr = frame.copy()\n",
    "\tfor x, y, z in frame_keypoints:\n",
    "\t\t# check if x or y are masked\n",
    "\t\tif np.ma.is_masked(x) or np.ma.is_masked(y) or np.isnan(x) or np.isnan(y):\n",
    "\t\t\t# print(x.data, y.data)\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\tx = int(x*w)\n",
    "\t\t\ty = int(y*h)\n",
    "\t\t\tfr[y-size:y+size:,x-size:x+size] = color if color is not None else 255-fr[y-size:y+size:,x-size:x+size]\n",
    "\treturn fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read processed keys from test.npy\n",
    "processed_keys = np.load(\"test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 543, 3)\n"
     ]
    }
   ],
   "source": [
    "h, w = 480, 720\n",
    "video = np.zeros((processed_keys.shape[0], h, w, 3), np.dtype('uint8'))\n",
    "print(processed_keys.shape)\n",
    "for i_frame in range(processed_keys.shape[0]):\n",
    "\tvideo[i_frame] = draw_keypoints(video[i_frame], processed_keys[i_frame], h, w, size=2)\n",
    "store_video(video, \"example_mp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.4614348\n",
       "y: 0.24736053\n",
       "z: -0.44210353\n",
       "visibility: 0.99998236"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints[0].pose_landmarks.landmark[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle store the keypoints\n",
    "import pickle\n",
    "\n",
    "with open(f\"{OUT_DIR}/example_mp.pickle\", \"wb\") as f:\n",
    "\tpickle.dump(keypoints, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slt_datasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
